{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('khayyammolana.txt', 'rb').read().decode(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|برخیز بتا'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabolaries = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " '\\r',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " '.',\n",
       " ':',\n",
       " '|',\n",
       " '\\xa0',\n",
       " '«',\n",
       " '»',\n",
       " '،',\n",
       " '؛',\n",
       " '؟',\n",
       " 'ء',\n",
       " 'آ',\n",
       " 'أ',\n",
       " 'ؤ',\n",
       " 'إ',\n",
       " 'ئ',\n",
       " 'ا',\n",
       " 'ب',\n",
       " 'ة',\n",
       " 'ت',\n",
       " 'ث',\n",
       " 'ج',\n",
       " 'ح',\n",
       " 'خ',\n",
       " 'د',\n",
       " 'ذ',\n",
       " 'ر',\n",
       " 'ز',\n",
       " 'س',\n",
       " 'ش',\n",
       " 'ص',\n",
       " 'ض',\n",
       " 'ط',\n",
       " 'ظ',\n",
       " 'ع',\n",
       " 'غ',\n",
       " 'ـ',\n",
       " 'ف',\n",
       " 'ق',\n",
       " 'ل',\n",
       " 'م',\n",
       " 'ن',\n",
       " 'ه',\n",
       " 'و',\n",
       " 'ي',\n",
       " 'ً',\n",
       " 'ٌ',\n",
       " 'ٍ',\n",
       " 'َ',\n",
       " 'ُ',\n",
       " 'ِ',\n",
       " 'ّ',\n",
       " 'ْ',\n",
       " 'ٓ',\n",
       " 'ٔ',\n",
       " 'ٰ',\n",
       " 'ٱ',\n",
       " 'پ',\n",
       " 'چ',\n",
       " 'ژ',\n",
       " 'ک',\n",
       " 'گ',\n",
       " 'ۀ',\n",
       " 'ی',\n",
       " 'ۡ',\n",
       " '\\u200f']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabolaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabolaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2index = {u:i for i, u in enumerate(vocabolaries)}\n",
    "index2char = np.array(vocabolaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " '\\r': 1,\n",
       " ' ': 2,\n",
       " '!': 3,\n",
       " '\"': 4,\n",
       " '.': 5,\n",
       " ':': 6,\n",
       " '|': 7,\n",
       " '\\xa0': 8,\n",
       " '«': 9,\n",
       " '»': 10,\n",
       " '،': 11,\n",
       " '؛': 12,\n",
       " '؟': 13,\n",
       " 'ء': 14,\n",
       " 'آ': 15,\n",
       " 'أ': 16,\n",
       " 'ؤ': 17,\n",
       " 'إ': 18,\n",
       " 'ئ': 19,\n",
       " 'ا': 20,\n",
       " 'ب': 21,\n",
       " 'ة': 22,\n",
       " 'ت': 23,\n",
       " 'ث': 24,\n",
       " 'ج': 25,\n",
       " 'ح': 26,\n",
       " 'خ': 27,\n",
       " 'د': 28,\n",
       " 'ذ': 29,\n",
       " 'ر': 30,\n",
       " 'ز': 31,\n",
       " 'س': 32,\n",
       " 'ش': 33,\n",
       " 'ص': 34,\n",
       " 'ض': 35,\n",
       " 'ط': 36,\n",
       " 'ظ': 37,\n",
       " 'ع': 38,\n",
       " 'غ': 39,\n",
       " 'ـ': 40,\n",
       " 'ف': 41,\n",
       " 'ق': 42,\n",
       " 'ل': 43,\n",
       " 'م': 44,\n",
       " 'ن': 45,\n",
       " 'ه': 46,\n",
       " 'و': 47,\n",
       " 'ي': 48,\n",
       " 'ً': 49,\n",
       " 'ٌ': 50,\n",
       " 'ٍ': 51,\n",
       " 'َ': 52,\n",
       " 'ُ': 53,\n",
       " 'ِ': 54,\n",
       " 'ّ': 55,\n",
       " 'ْ': 56,\n",
       " 'ٓ': 57,\n",
       " 'ٔ': 58,\n",
       " 'ٰ': 59,\n",
       " 'ٱ': 60,\n",
       " 'پ': 61,\n",
       " 'چ': 62,\n",
       " 'ژ': 63,\n",
       " 'ک': 64,\n",
       " 'گ': 65,\n",
       " 'ۀ': 66,\n",
       " 'ی': 67,\n",
       " 'ۡ': 68,\n",
       " '\\u200f': 69}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.str_('\\r')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2char[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_as_integer = np.array([char2index[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 21, 30, ..., 44,  1,  0], shape=(476563,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|\n",
      "ب\n",
      "ر\n",
      "خ\n",
      "ی\n",
      "ز\n",
      " \n",
      "ب\n",
      "ت\n",
      "ا\n"
     ]
    }
   ],
   "source": [
    "for i in char_dataset.take(10):\n",
    "    print(index2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=TensorSpec(shape=(101,), dtype=tf.int64, name=None)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = char_dataset.batch(101, drop_remainder=True)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> |برخیز بتا بیا ز بهر دل ما\n",
      "|حل کن به جمال خویشتن مشکل ما\n",
      "|یک کوزه شراب تا به هم نوش کنیم\n",
      "|زآن پیش \n",
      "---> که کوزه ها کنند از گل ما\n",
      "|چون عهده نمی شود کسی فردا را\n",
      "|حالی خوش دار این دل پر سودا را\n",
      "|می نوش به \n",
      "---> ماهتاب ای ماه که ماه\n",
      "|بسیار بتابد و نیابد ما را\n",
      "|قرآن که مهین کلام خوانند آن را\n",
      "|گه گاه نه بر دوام\n"
     ]
    }
   ],
   "source": [
    "for i in sequences.take(3):\n",
    "    print('--->', ''.join(index2char[i.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sit(batch):\n",
    "    input_text = batch[:-1]\n",
    "    target_text = batch[1:]\n",
    "    return input_text, target_text\n",
    "dataset = sequences.map(sit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=(TensorSpec(shape=(100,), dtype=tf.int64, name=None), TensorSpec(shape=(100,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|برخیز بتا بیا ز بهر دل ما\n",
      "|حل کن به جمال خویشتن مشکل ما\n",
      "|یک کوزه شراب تا به هم نوش کنیم\n",
      "|زآن پیش\n",
      "برخیز بتا بیا ز بهر دل ما\n",
      "|حل کن به جمال خویشتن مشکل ما\n",
      "|یک کوزه شراب تا به هم نوش کنیم\n",
      "|زآن پیش \n"
     ]
    }
   ],
   "source": [
    "for i in dataset.take(1):\n",
    "    print(''.join(index2char[i[0].numpy()]))\n",
    "    print(''.join(index2char[i[1].numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.batch(64, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabolaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabolary_size = len(vocabolaries)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocabolary_size, embedding_dim),\n",
    "    tf.keras.layers.GRU(rnn_units, return_sequences=True),\n",
    "    tf.keras.layers.Dense(vocabolary_size)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step\n",
      "[[ 0.00970264 -0.01839882  0.00388445 ... -0.00793354  0.00108997\n",
      "   0.00679773]\n",
      " [ 0.0045926  -0.01137484 -0.00508215 ... -0.00638043 -0.00175606\n",
      "   0.00092236]\n",
      " [ 0.01077413 -0.00790394  0.00195149 ... -0.00628281 -0.01318328\n",
      "   0.00034212]\n",
      " ...\n",
      " [ 0.01813973  0.00461157 -0.00334634 ... -0.01713279 -0.01017357\n",
      "   0.00250647]\n",
      " [ 0.00012701 -0.00398188  0.01510931 ... -0.0059436   0.00957258\n",
      "   0.01141557]\n",
      " [-0.0212269   0.01074433  0.0119169  ... -0.00751193 -0.00436388\n",
      "   0.01279578]]\n"
     ]
    }
   ],
   "source": [
    "for input_text, target_text in dataset.take(1):\n",
    "    output = model.predict(input_text)\n",
    "    print(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 1), dtype=int64, numpy=\n",
       "array([[25],\n",
       "       [16],\n",
       "       [31],\n",
       "       [22],\n",
       "       [25],\n",
       "       [45],\n",
       "       [ 7],\n",
       "       [17],\n",
       "       [32],\n",
       "       [27],\n",
       "       [55],\n",
       "       [60],\n",
       "       [44],\n",
       "       [30],\n",
       "       [59],\n",
       "       [28],\n",
       "       [32],\n",
       "       [65],\n",
       "       [29],\n",
       "       [64],\n",
       "       [69],\n",
       "       [51],\n",
       "       [ 9],\n",
       "       [14],\n",
       "       [42],\n",
       "       [40],\n",
       "       [ 5],\n",
       "       [49],\n",
       "       [18],\n",
       "       [25],\n",
       "       [20],\n",
       "       [ 6],\n",
       "       [40],\n",
       "       [ 0],\n",
       "       [63],\n",
       "       [42],\n",
       "       [38],\n",
       "       [69],\n",
       "       [32],\n",
       "       [16],\n",
       "       [42],\n",
       "       [ 9],\n",
       "       [35],\n",
       "       [41],\n",
       "       [50],\n",
       "       [40],\n",
       "       [67],\n",
       "       [48],\n",
       "       [56],\n",
       "       [56],\n",
       "       [38],\n",
       "       [33],\n",
       "       [56],\n",
       "       [38],\n",
       "       [ 2],\n",
       "       [27],\n",
       "       [12],\n",
       "       [43],\n",
       "       [58],\n",
       "       [65],\n",
       "       [65],\n",
       "       [15],\n",
       "       [52],\n",
       "       [49],\n",
       "       [29],\n",
       "       [48],\n",
       "       [60],\n",
       "       [11],\n",
       "       [ 0],\n",
       "       [68],\n",
       "       [29],\n",
       "       [34],\n",
       "       [27],\n",
       "       [53],\n",
       "       [ 9],\n",
       "       [24],\n",
       "       [59],\n",
       "       [12],\n",
       "       [66],\n",
       "       [37],\n",
       "       [68],\n",
       "       [67],\n",
       "       [ 1],\n",
       "       [44],\n",
       "       [26],\n",
       "       [22],\n",
       "       [34],\n",
       "       [51],\n",
       "       [68],\n",
       "       [39],\n",
       "       [15],\n",
       "       [15],\n",
       "       [39],\n",
       "       [21],\n",
       "       [56],\n",
       "       [28],\n",
       "       [20],\n",
       "       [16],\n",
       "       [33],\n",
       "       [44]])>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "si = tf.random.categorical(output[0], num_samples=1)\n",
    "si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25, 16, 31, 22, 25, 45,  7, 17, 32, 27, 55, 60, 44, 30, 59, 28, 32,\n",
       "       65, 29, 64, 69, 51,  9, 14, 42, 40,  5, 49, 18, 25, 20,  6, 40,  0,\n",
       "       63, 42, 38, 69, 32, 16, 42,  9, 35, 41, 50, 40, 67, 48, 56, 56, 38,\n",
       "       33, 56, 38,  2, 27, 12, 43, 58, 65, 65, 15, 52, 49, 29, 48, 60, 11,\n",
       "        0, 68, 29, 34, 27, 53,  9, 24, 59, 12, 66, 37, 68, 67,  1, 44, 26,\n",
       "       22, 34, 51, 68, 39, 15, 15, 39, 21, 56, 28, 20, 16, 33, 44])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.squeeze(si, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'جأزةجن|ؤسخّٱمرٰدسگذک\\u200fٍ«ءقـ.ًإجا:ـ\\nژقع\\u200fسأق«ضفٌـیيْْعشْع خ؛لٔگگآًَذيٱ،\\nۡذصخُ«ثٰ؛ۀظۡی\\rمحةصٍۡغآآغبْداأشم'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(index2char[tf.squeeze(si, axis=-1).numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.44888499e-03,  1.11714844e-02,  6.47663930e-03,  9.44418274e-03,\n",
       "       -7.54784467e-03, -3.63717368e-03, -1.14993555e-02,  7.40472367e-03,\n",
       "       -1.13251116e-02, -2.98008230e-03, -9.63390153e-03,  5.49731497e-03,\n",
       "        3.09667340e-03, -7.55351502e-03,  2.44723260e-03, -1.21576563e-02,\n",
       "       -1.60848070e-03,  1.57391708e-02, -6.40200870e-03, -1.44026373e-02,\n",
       "       -4.29360196e-04,  5.34749543e-03,  5.39186411e-04,  1.43774934e-02,\n",
       "       -1.46316225e-02, -2.99174944e-03,  1.09978244e-02,  2.35257624e-03,\n",
       "        2.87530501e-03, -1.02336779e-02,  1.88457742e-02,  2.88052927e-03,\n",
       "       -9.23661981e-03,  9.77088977e-03,  7.03654904e-03, -7.07607251e-03,\n",
       "        8.46801046e-03,  1.85479969e-03, -1.80518988e-03,  5.10771666e-03,\n",
       "        3.51741863e-03, -8.59439187e-03,  7.60383578e-03,  2.19827588e-03,\n",
       "       -3.80006531e-06,  6.12420309e-03, -1.11474958e-03, -2.96268379e-03,\n",
       "        3.31144454e-03,  4.69873706e-03,  1.15257939e-02, -1.00553706e-02,\n",
       "        3.29412520e-04, -5.42816240e-04,  8.94447044e-03, -1.02306027e-02,\n",
       "        1.07701840e-02,  2.62494665e-03,  1.97587516e-02, -5.84758958e-03,\n",
       "       -1.50719867e-03, -4.29891329e-03, -8.54173116e-03,  2.39059655e-03,\n",
       "        6.77530514e-03,  2.64473842e-04, -8.73207394e-03, -3.50408442e-03,\n",
       "        2.50498671e-03,  1.68634690e-02], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">17,920</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,938,304</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">71,750</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │        \u001b[38;5;34m17,920\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │     \u001b[38;5;34m3,938,304\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m70\u001b[0m)          │        \u001b[38;5;34m71,750\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,027,974</span> (15.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,027,974\u001b[0m (15.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,027,974</span> (15.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,027,974\u001b[0m (15.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_f(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "model.compile(optimizer='adam', loss=loss_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath='khayyammolana/checkpoints', save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 489ms/step - loss: 2.2269\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\salim\\Desktop\\ProgramingProjects\\DataMining\\mlenv\\Lib\\site-packages\\keras\\src\\callbacks\\model_checkpoint.py:276: UserWarning: Can save best model only with val_loss available.\n",
      "  if self._should_save_model(epoch, batch, logs, filepath):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/73\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 522ms/step - loss: 2.1887"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\salim\\Desktop\\ProgramingProjects\\DataMining\\mlenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\salim\\Desktop\\ProgramingProjects\\DataMining\\mlenv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\salim\\Desktop\\ProgramingProjects\\DataMining\\mlenv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\salim\\Desktop\\ProgramingProjects\\DataMining\\mlenv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\salim\\Desktop\\ProgramingProjects\\DataMining\\mlenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\salim\\Desktop\\ProgramingProjects\\DataMining\\mlenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\salim\\Desktop\\ProgramingProjects\\DataMining\\mlenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\salim\\Desktop\\ProgramingProjects\\DataMining\\mlenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\salim\\Desktop\\ProgramingProjects\\DataMining\\mlenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\salim\\Desktop\\ProgramingProjects\\DataMining\\mlenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\salim\\Desktop\\ProgramingProjects\\DataMining\\mlenv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\salim\\Desktop\\ProgramingProjects\\DataMining\\mlenv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=50, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'khayyammolana/checkpoints'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint('khayyammolana/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocabolary_size, embedding_dim),\n",
    "    tf.keras.layers.GRU(rnn_units, return_sequences=True),\n",
    "    tf.keras.layers.Dense(vocabolary_size)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are loading weights into a model that has not yet been built. Try building the model first by calling it on some data or by using `build()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel3\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mkhayyammolana/checkpoints/my_model.weights.h5\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\salim\\Desktop\\ProgramingProjects\\DataMining\\mlenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\salim\\Desktop\\ProgramingProjects\\DataMining\\mlenv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:577\u001b[39m, in \u001b[36mload_weights_only\u001b[39m\u001b[34m(model, filepath, skip_mismatch, objects_to_skip)\u001b[39m\n\u001b[32m    572\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load the weights of a model from a filepath (.keras or .weights.h5).\u001b[39;00m\n\u001b[32m    573\u001b[39m \n\u001b[32m    574\u001b[39m \u001b[33;03mNote: only supports h5 for now.\u001b[39;00m\n\u001b[32m    575\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    576\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model.built:\n\u001b[32m--> \u001b[39m\u001b[32m577\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    578\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou are loading weights into a model that has not yet been built. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    579\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTry building the model first by calling it on some data or \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    580\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mby using `build()`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    581\u001b[39m     )\n\u001b[32m    583\u001b[39m archive = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    584\u001b[39m tmp_dir = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: You are loading weights into a model that has not yet been built. Try building the model first by calling it on some data or by using `build()`."
     ]
    }
   ],
   "source": [
    "model3.load_weights(\"khayyammolana/checkpoints/my_model.weights.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 256)         12032     \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (None, None, 1024)        3938304   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, None, 47)          48175     \n",
      "=================================================================\n",
      "Total params: 3,998,511\n",
      "Trainable params: 3,998,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 23), dtype=int32, numpy=\n",
       "array([[10, 34,  1, 33,  9, 32,  1, 16, 17,  9, 35, 33, 17,  1, 14,  9,\n",
       "        33,  1, 35,  1, 16, 19, 17]], dtype=int32)>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_generate = 1000\n",
    "first_string = 'به نام خداوند جان و خرد'\n",
    "input_eval = [char2index[s] for s in first_string]\n",
    "input_eval = tf.expand_dims(input_eval, 0)\n",
    "input_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n",
      "17\n",
      "19\n",
      "1\n",
      "10\n",
      "46\n",
      "9\n",
      "33\n",
      "1\n",
      "32\n",
      "9\n",
      "33\n",
      "17\n",
      "1\n",
      "9\n",
      "20\n",
      "1\n",
      "9\n",
      "10\n",
      "17\n",
      "46\n",
      "31\n",
      "1\n",
      "35\n",
      "1\n",
      "45\n",
      "32\n",
      "0\n",
      "3\n",
      "33\n",
      "9\n",
      "30\n",
      "34\n",
      "40\n",
      "1\n",
      "14\n",
      "21\n",
      "32\n",
      "1\n",
      "35\n",
      "31\n",
      "46\n",
      "1\n",
      "19\n",
      "9\n",
      "1\n",
      "10\n",
      "21\n",
      "1\n",
      "10\n",
      "17\n",
      "46\n",
      "17\n",
      "0\n",
      "3\n",
      "42\n",
      "35\n",
      "33\n",
      "1\n",
      "10\n",
      "32\n",
      "9\n",
      "33\n",
      "17\n",
      "1\n",
      "9\n",
      "20\n",
      "1\n",
      "16\n",
      "10\n",
      "19\n",
      "1\n",
      "6\n",
      "28\n",
      "9\n",
      "20\n",
      "1\n",
      "44\n",
      "19\n",
      "17\n",
      "0\n",
      "3\n",
      "45\n",
      "9\n",
      "34\n",
      "1\n",
      "10\n",
      "28\n",
      "17\n",
      "1\n",
      "9\n",
      "20\n",
      "1\n",
      "17\n",
      "22\n",
      "32\n",
      "33\n",
      "9\n",
      "33\n",
      "1\n",
      "9\n",
      "46\n",
      "33\n",
      "1\n",
      "19\n",
      "9\n",
      "1\n",
      "22\n",
      "33\n",
      "9\n",
      "21\n",
      "0\n",
      "3\n",
      "42\n",
      "35\n",
      "33\n",
      "1\n",
      "10\n",
      "17\n",
      "9\n",
      "33\n",
      "17\n",
      "1\n",
      "42\n",
      "19\n",
      "16\n",
      "1\n",
      "19\n",
      "9\n",
      "1\n",
      "32\n",
      "33\n",
      "1\n",
      "17\n",
      "19\n",
      "1\n",
      "17\n",
      "31\n",
      "46\n",
      "0\n",
      "3\n",
      "45\n",
      "19\n",
      "1\n",
      "33\n",
      "32\n",
      "9\n",
      "20\n",
      "1\n",
      "35\n",
      "1\n",
      "19\n",
      "35\n",
      "20\n",
      "1\n",
      "32\n",
      "46\n",
      "1\n",
      "6\n",
      "19\n",
      "17\n",
      "1\n",
      "21\n",
      "16\n",
      "33\n",
      "0\n",
      "3\n",
      "42\n",
      "35\n",
      "33\n",
      "1\n",
      "33\n",
      "46\n",
      "44\n",
      "1\n",
      "35\n",
      "1\n",
      "10\n",
      "17\n",
      "22\n",
      "1\n",
      "20\n",
      "46\n",
      "33\n",
      "1\n",
      "33\n",
      "9\n",
      "33\n",
      "1\n",
      "42\n",
      "19\n",
      "9\n",
      "0\n",
      "3\n",
      "34\n",
      "19\n",
      "1\n",
      "42\n",
      "34\n",
      "1\n",
      "10\n",
      "19\n",
      "1\n",
      "12\n",
      "21\n",
      "35\n",
      "46\n",
      "19\n",
      "1\n",
      "42\n",
      "46\n",
      "33\n",
      "34\n",
      "1\n",
      "31\n",
      "14\n",
      "12\n",
      "1\n",
      "35\n",
      "1\n",
      "21\n",
      "16\n",
      "9\n",
      "33\n",
      "1\n",
      "35\n",
      "1\n",
      "19\n",
      "35\n",
      "15\n",
      "1\n",
      "34\n",
      "21\n",
      "12\n",
      "0\n",
      "3\n",
      "6\n",
      "33\n",
      "1\n",
      "9\n",
      "13\n",
      "19\n",
      "1\n",
      "32\n",
      "46\n",
      "1\n",
      "10\n",
      "9\n",
      "20\n",
      "46\n",
      "1\n",
      "17\n",
      "16\n",
      "35\n",
      "46\n",
      "22\n",
      "1\n",
      "35\n",
      "1\n",
      "17\n",
      "22\n",
      "9\n",
      "17\n",
      "0\n",
      "3\n",
      "17\n",
      "19\n",
      "1\n",
      "32\n",
      "46\n",
      "9\n",
      "33\n",
      "1\n",
      "16\n",
      "35\n",
      "9\n",
      "10\n",
      "1\n",
      "14\n",
      "21\n",
      "12\n",
      "1\n",
      "35\n",
      "1\n",
      "45\n",
      "9\n",
      "34\n",
      "1\n",
      "6\n",
      "33\n",
      "1\n",
      "16\n",
      "31\n",
      "46\n",
      "1\n",
      "14\n",
      "35\n",
      "1\n",
      "10\n",
      "19\n",
      "17\n",
      "1\n",
      "9\n",
      "46\n",
      "33\n",
      "0\n",
      "3\n",
      "41\n",
      "46\n",
      "22\n",
      "1\n",
      "6\n",
      "19\n",
      "17\n",
      "1\n",
      "30\n",
      "19\n",
      "23\n",
      "1\n",
      "17\n",
      "46\n",
      "33\n",
      "1\n",
      "19\n",
      "9\n",
      "1\n",
      "35\n",
      "9\n",
      "1\n",
      "19\n",
      "34\n",
      "9\n",
      "33\n",
      "0\n",
      "3\n",
      "42\n",
      "22\n",
      "32\n",
      "34\n",
      "40\n",
      "1\n",
      "16\n",
      "35\n",
      "33\n",
      "1\n",
      "19\n",
      "9\n",
      "1\n",
      "10\n",
      "29\n",
      "33\n",
      "1\n",
      "9\n",
      "20\n",
      "1\n",
      "19\n",
      "46\n",
      "45\n",
      "1\n",
      "9\n",
      "35\n",
      "0\n",
      "3\n",
      "10\n",
      "21\n",
      "1\n",
      "45\n",
      "19\n",
      "9\n",
      "20\n",
      "1\n",
      "6\n",
      "10\n",
      "21\n",
      "12\n",
      "1\n",
      "33\n",
      "30\n",
      "22\n",
      "9\n",
      "33\n",
      "1\n",
      "35\n",
      "1\n",
      "13\n",
      "10\n",
      "9\n",
      "10\n",
      "0\n",
      "3\n",
      "42\n",
      "35\n",
      "33\n",
      "44\n",
      "1\n",
      "6\n",
      "35\n",
      "9\n",
      "20\n",
      "1\n",
      "16\n",
      "31\n",
      "30\n",
      "1\n",
      "9\n",
      "20\n",
      "1\n",
      "10\n",
      "46\n",
      "16\n",
      "1\n",
      "35\n",
      "1\n",
      "33\n",
      "35\n",
      "0\n",
      "3\n",
      "10\n",
      "9\n",
      "1\n",
      "22\n",
      "32\n",
      "9\n",
      "1\n",
      "9\n",
      "20\n",
      "1\n",
      "16\n",
      "31\n",
      "30\n",
      "1\n",
      "9\n",
      "46\n",
      "33\n",
      "1\n",
      "21\n",
      "35\n",
      "20\n",
      "46\n",
      "1\n",
      "35\n",
      "1\n",
      "17\n",
      "21\n",
      "12\n",
      "0\n",
      "3\n",
      "17\n",
      "19\n",
      "1\n",
      "10\n",
      "46\n",
      "9\n",
      "10\n",
      "9\n",
      "33\n",
      "34\n",
      "9\n",
      "46\n",
      "1\n",
      "10\n",
      "46\n",
      "1\n",
      "42\n",
      "33\n",
      "17\n",
      "46\n",
      "1\n",
      "22\n",
      "44\n",
      "21\n",
      "12\n",
      "0\n",
      "3\n",
      "9\n",
      "33\n",
      "17\n",
      "19\n",
      "1\n",
      "6\n",
      "1\n",
      "32\n",
      "9\n",
      "17\n",
      "19\n",
      "1\n",
      "32\n",
      "17\n",
      "34\n",
      "1\n",
      "17\n",
      "9\n",
      "17\n",
      "9\n",
      "33\n",
      "1\n",
      "46\n",
      "44\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "text_generated = ['به نام خداوند جان و خرد']\n",
    "for i in range(500):\n",
    "    predictions = model_2.predict(input_eval)\n",
    "    predictions = tf.squeeze(predictions, 0)\n",
    "#     predicted_ids = tf.random.categorical(predictions, num_samples=1).numpy()\n",
    "    predicted_ids = np.array(predictions.numpy()).argmax(axis=1).reshape(-1, 1)[-1][0]\n",
    "    print(predicted_ids)\n",
    "    message = np.append(input_eval[0].numpy(), predicted_ids)[1:]\n",
    "    input_eval = tf.expand_dims(message, 0)\n",
    "    text_generated.append(index2char[predicted_ids])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['به نام خداوند جان و خرد',\n",
       " '|در بیان ماند از ابدیل و گم',\n",
       " '|ناقهٔ جسم ولی را بس بدید',\n",
       " '|چون بماند از خبر آغاز کرد',\n",
       " '|گاه بغد از دشمنان این را شناس',\n",
       " '|چون بداند چرخ را من در دلی',\n",
       " '|گر نماز و روز می آرد سخن',\n",
       " '|چون نیک و بدش زین نان چرا',\n",
       " '|هر چه بر تسویر چینه لجت و سخان و روح هست',\n",
       " '|آن اثر می بازی دخویش و دشاد',\n",
       " '|در میان خواب جست و گاه آن خلی جو برد این',\n",
       " '|پیش آرد قرص دین را وا رهان',\n",
       " '|چشمهٔ خون را بفن از ریگ او',\n",
       " '|بس گراز آبست نقشان و ثباب',\n",
       " '|چونک آواز خلق از بیخ و نو',\n",
       " '|با شما از خلق این سوزی و دست',\n",
       " '|در بیابانهای بی چندی شکست',\n",
       " '|اندر آ مادر مده دادان یکی']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(text_generated).split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "به نام خداوند جان و خرد\n",
      "|در بیان ماند از ابدیل و گم\n",
      "|ناقهٔ جسم ولی را بس بدید\n",
      "|چون بماند از خبر آغاز کرد\n",
      "|گاه بغد از دشمنان این را شناس\n",
      "|چون بداند چرخ را من در دلی\n",
      "|گر نماز و روز می آرد سخن\n",
      "|چون نیک و بدش زین نان چرا\n",
      "|هر چه بر تسویر چینه لجت و سخان و روح هست\n",
      "|آن اثر می بازی دخویش و دشاد\n",
      "|در میان خواب جست و گاه آن خلی جو برد این\n",
      "|پیش آرد قرص دین را وا رهان\n",
      "|چشمهٔ خون را بفن از ریگ او\n",
      "|بس گراز آبست نقشان و ثباب\n",
      "|چونک آواز خلق از بیخ و نو\n",
      "|با شما از خلق این سوزی و دست\n",
      "|در بیابانهای بی چندی شکست\n",
      "|اندر آ مادر مده دادان یکی\n"
     ]
    }
   ],
   "source": [
    "for i in ''.join(text_generated).split('\\n'):\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
